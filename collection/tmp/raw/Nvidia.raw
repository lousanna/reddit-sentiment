he anticipated ops submission at [1\:01\:14](http://www.youtube.com/watch?feature=player_detailpage&v=mshbp3opasa#t=3674s) in response to the last comment from a current nvidia developer.>i like being outrageous at times. i guarantee you that if you make this video available on the internet there will be thousands of people that are really upset.
63
the funny thing is, that in the end the last question comes from a guy who just joined nvidia to do opensource work there. *"even though you gave me the finger, i still thank you!"* ;-)
89
i wonder in what ways nvidia is bad to work with?edit: why the downvotes? this seems like a relevant question, no?
34
while linus public complaints can be irritating, this, this was truly satisfying. let us all agree: fuck you, nvidia.
14
although i wish hed be more polite about it, i tend to agree. i try to avoid buying anything containing nvidia. unfortunately, a lot of laptops have nvidia chips in them.
7
can anyone explain to me how to reconcile this with this article on reddit [nvidia drivers 302.17 certified](http://www.reddit.com/r/linux/comments/v4z0x/nvidia_drivers_30217_certified/)?  does this mean coincidentally the problem is solved just after linus gave this interview?
2
powervr is worse than nvidia.
1
im pretty sure you dont win future friends by showing the middle finger to the people you work with, even if they deserve it.i mean, its a huge pr problem for a company: linus has a lot of power in his words. imagine some smaller company really trying to make a mark with linux and then linus flips them off because he had a bad morning. you all have read how he flames with his emails.i dont care how bad a company nvidia is. this just makes me a bit uneasy im using gnu/linux, because i dont want to be associated with this.edit: and while you can downvote me for not agreeing with the hive, i just want you to know there are open source developers who seriously think linus should often just shut up.
-4
for linux pc gaming.. it must be nvidia..
0
a project i am on at my new job is working closely with nvidia to provide a solution, is running on linux clusters.  omg it looks so badass.  so, nvidia isnt all fuckable.
1
and here i thought between ati and nvidia, nvidia was the only company that had decent drivers for their stuff in linux. what am i missing?
0
what would really be funny is if nvidia decided to say fuck you to linux and stopped making drivers for linux.
-1
if nvidia is going to support freesync, nocompany will make g-sync monitors.
88
i keep seeing people say "vote with your wallet! buy more freesync monitors!" but how at all do you think that will affect nvidia? they dont give a shit how many freesync monitors are sold, they care about their own cards selling. the only way nvidia is going to give a shit about freesync is if people stop buying nvidia cards. since they are (for the most part) better than amd cards, good luck.
6
if nvidia supported freesync i would but a 1070 asap.
6
everyone is pretty convinced nvidia will never do this, but consider this: i would have bought a 1080 weeks ago if it was compatible with my current-gen freesync monitor. instead im holding out for the rx 290 so i dont have to buy a new monitor with my new video card. its my understanding that freesync and g-sync are so close in tech... im a little surprised no one has patched support into drivers yet (it must be much more difficult than i assume).
2
its the reason im hesitating to buy a new monitor g-sync is nvidia only and freesync amd. i just want one to support both..
2
theres a reason nvidia doesnt support freesync, and its not that people dont want them to
2
hdtvs wont support shit until ms and sony decide they want adaptive sync on their consoles and then pushing them out.  the realistic best hope is for sony to push a console that does hdr and adaptive sync since they can then make a gaming tv to go with it as a bundle.  then hopefully other tv manufacturers jump into that market.on the monitor side, it would be nice but many manufacturers have somewhat half ass at best implementations of free-sync given its flexibility as a standard.  its not like g-sync where nvidia can use their certification process to dictate extremely specific details.  free-sync would probably grow more if amd created a tighter spec.  if i have a display that goes g-sync and freesync, but the freesync implementation is shit ill just keep buying team green and using the g-sync ability.  so the freesync on the monitor is mostly worthless.
1
nvidia isnt going to support it, unless they end up being the odd man out.    consoles arent going to support it this generation, and tv makers arent going to support it until it is a industry standard in all three major consoles, intel, nvidia, and arm socs have fully supported in all their intigrated gpus for a couple years.
1
iirc nvidia was talking about supporting it a while back but just never did
1
i regret getting gtc 1060 instead of rx480 even tho i dont have freesync, but i was impatient. couldnt get viewsonic xg2401 so ended up with lg 24gm77, i wouldnt use free sync much but still i dont like nvidia policy
1
whats that? youre asking nvidia to give up their sweet, sweet licensing fee when they have overwhelming market share? yeah, good luck with that.
1
lolthese petitions do nothing and nvidia isnt stupid.
0
nvidia knows whats up.
1
nvidia had an open source guy?  i must have missed him while staring at the miles of proprietary.
117
hey everyone!as always, we sat in on the latest nvidia press conference (last week) to hear about the companys new updates. there was another conference -- one held by amd -- just a couple days later. the nvidia information was under embargo until now, the amd embargo lifts tomorrow. this is all hot off the heels of gdc and gtc, where we spoke to both companies about things like titan z and the firepro w9100. you can find my buildapc thread about titan z & pascal [over here](http://www.reddit.com/r/buildapc/comments/21c8a9/full_nvidia_keynote_writeup_nvidia_titan_z_specs/) where i answered some questions. if youve got more questions, leave them in this thread! the most recent conference primarily covered these topics:**gfe 2.0 update**- geforce experience 2.0.- battery boost for 800m laptops.- shadowplay ships on laptops.- gamestream ships on laptops.- shadowplay desktop capture (no viewport limiter right now).- support for 20 new games.**shield**- new update for shield & gfe.- internet game streaming. streaming can now be done over wireless with minimal latency. 5mbps down/up recommended for best play.- shield can boot the remote system from s3 (maybe s4, havent tested), log in, and launch a compatible title.**337.50 beta drivers - inordinate performance gains**heres probably the most interesting/compelling stuff for most of us.- nvidia claims 337.50 shows performance improvements upwards of 71% for sli and 64% for single gpus.- nvidia notes that these "arent normal driver updates," pointing out that these gains are a result of working closely with microsoft (dx 11).- 337.50 meets or bests amd mantle performance in bf4, thief, and starswarm (which nvidia calls a "synthetic game benchmark with the sole purpose of showcasing the intention of mantle in the best light possible."- internally (335.23 to 337.50), performance gains are fairly massive (see all benchmarks in post; [heres one direct image example](http://media.gamersnexus.net/images/media/2014/nvidia/nv-dx13.jpg)).**getting feisty - dx12 "is the future."**- nvidia took an incredibly aggressive, forward stance that explicitly mentioned mantle and amd several times - normally they let us do more "reading between the lines."- nvidia had several very subtle amd slams in their slides. things like "the api of choice," or "works within the industry standard: directx 11," etc. these arent necessarily incorrect, just sort of amusing / humorous to me as someone who normally sees them fighting in a less direct fashion.- nvidia was quick to point-out that only 11% of the discrete gpu install base supports mantle, meanwhile 78% of it supports dx 11 and, of those dx11 cards, 79% will support dx12.- pushing harder, it was then made clear that 100% of geforce gpus that support dx11 will support dx12, followed-up by a statement that 40% of amds dx11 gpus would support dx12 or currently support mantle.as for my thoughts, well, its getting a lot more direct and aggressive. i think the above indicates that. we spoke to amd shortly thereafter and asked about a few of these points, but it was made clear that amd didnt want to talk about anything related to directx 12. "guys," they told the press, "directx 12 is 21 months out."anyway, **the amd embargo lifts tomorrow** and will be talking primarily about the 295x2 gpu. i wont be making a separate post for that one since its a bit smaller and is also too soon, so if youve got questions now about it, leave them here and i will answer as soon as the embargo lifts. edit: all the drivers should be available today and gfe updates should be available shortly, if not today.
72
i thought [this](http://www.reddit.com/r/hardware/comments/22f6ze/nvidia_seeks_to_invalidate_mantle_driver_dx/cgm7i1j) was a good thread from /r/hardware:jmac said re: nvidias stance:>this seems so childish. there are a lot of people both in industry and from the peanut gallery that are taking shots at amd for a move that they obviously needed to make. they didnt have the luxury of waiting for the entire graphics industry to move things in this direction, their own products were hurting and they took it upon themselves to come up with a solution. there are no downsides to mantle existing, and to sit on the sidelines and say its not perfect is downright petty. also, i find it a bit ironic that the same claims could be used against g-sync.i thought he made a pretty good point and replied with:>amd has made a lot of strong plays recently. not all of them have gotten the reception / have worked as well as they could have, but there have been a lot of interesting developments outside of the usual gpus (which is nice). truaudio, freesync, and mantle are all good examples. the apu advancements in the form of huma, hsa, and synchronous queuing are also noteworthy. theyve needed to make these moves to get back into a more stable stance in the marketplace -- i actually think their marketing team is pretty strong right now.>amd didnt really directly comment on nvidia during their event, though nvidia was very aggressive / directly attempting to invalidate amd. normally its a lot more neutral (i.e. more talking about their own developments, with a few internal benchmarks thrown in vs. competitors).
47
i thought nvidia was pushing for more opengl support
10
not going to lie, im a little disappointed by the disparity here. they made such incredible claims but every third party verification i can track down doesnt really indicate the sort of sweeping improvement one mightve hoped from the tone of nvidias press conference. in fact, it just seems they optimized the d3d calls for poorly optimized games, which, while effective for those games, doesnt really equate to some secret sauce.on the plus side, im very excited that amd is able to have this level of impact on nvidia. i think its pretty apparent that nvidia knows that amd has the head start on huma, hsa, and close to the metal optimization. theyre trying desperately to prove that they can come close to these gains in directx, but as far as i can tell, they dont have a real api thats going to open up the ease of optimization theyre looking for until directx 12, which as amd points out, is still almost two years away. moreover, i think the technologies of huma and hsa and in some ways mantle, represent a very interesting prospect for the future. the developments over the next two years will be very interesting indeed (personally hoping for opengl and mantle to become the two competing technologies, or a directx implementation for linux [pipe-dreaming]).
40
337.50 beta download is up!http://www.nvidia.com/download/driverresults.aspx/74636/en-us
5
whenever i think amd gpus are right there nvidia always comes back with something that makes a new gpu purchase a no-brainer.  this is very exciting for those who are using nvidia hardware!
-7
